{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Visualization YOLO efficiency </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to have run the following commands before running this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original LISA dataset...\n",
      "Done.\n",
      "\n",
      "Pre-processing extension LISA dataset...\n",
      "Done.\n",
      "\n",
      "Creating train and test txt files...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "! python pre_process_lisa.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also be sure to have the following folder architecture:\n",
    "- LISA_TS/\n",
    "    - aiua120214-0/\n",
    "    - aiua120214-1/\n",
    "    - ...\n",
    "    - readme.txt\n",
    "    - videoSources.txt\n",
    "    \n",
    "    \n",
    "- LISA_TS_extension/\n",
    "    - 2014-04-24_10-59/\n",
    "    - 2014-04-24_11-43/\n",
    "    - ...\n",
    "    - 2014-07-11_13-47/\n",
    "    - allTrainingAnnotations.csv\n",
    "    \n",
    "    \n",
    "- weights/\n",
    "    - trained_weights_final.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(To obtain *trained_weights_final.h5* either:\n",
    "- train the network by running *python train.py* (follow the readme instructions for more information, it needs a GPU and takes ~2 days for 150 epochs)\n",
    "- or ask Louis for the last trained weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Loss evolution in training</h2>(On the training dataset and the validation dataset)\n",
    "\n",
    "abscisse units: epoch\n",
    "screenshots from tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td> <img src=\"screenshots/loss.png\" width=500> </td>\n",
    "    <td> <img src=\"screenshots/val_loss.png\" width=500> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Utils definition </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from yolo import YOLO\n",
    "from yolo3.utils import letterbox_image\n",
    "from yolo3.model import yolo_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOPlus(YOLO):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(YOLOPlus, self).__init__(**kwargs)\n",
    "\n",
    "    def detect_most_confident_sign(self, image):\n",
    "        \"\"\"\n",
    "        Will draw a bounding box where the neural network is the most confident\n",
    "        there is a sign. It will return the image, the class, the condifence in the box,\n",
    "        and the box itself.\n",
    "        \"\"\"\n",
    "        start = timer()\n",
    "\n",
    "        if self.model_image_size != (None, None):\n",
    "            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))\n",
    "        else:\n",
    "            new_image_size = (image.width - (image.width % 32),\n",
    "                              image.height - (image.height % 32))\n",
    "            boxed_image = letterbox_image(image, new_image_size)\n",
    "        image_data = np.array(boxed_image, dtype='float32')\n",
    "\n",
    "        #print(image_data.shape)\n",
    "        image_data /= 255.\n",
    "        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "        out_boxes, out_scores, out_classes = self.sess.run(\n",
    "            [self.boxes, self.scores, self.classes],\n",
    "            feed_dict={\n",
    "                self.yolo_model.input: image_data,\n",
    "                self.input_image_shape: [image.size[1], image.size[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "\n",
    "        #print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n",
    "\n",
    "        font = ImageFont.truetype(font='font/FiraMono-Medium.otf',\n",
    "                    size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "        thickness = (image.size[0] + image.size[1]) // 300\n",
    "        \n",
    "        if len(out_scores) > 0:\n",
    "            max_score = max(out_scores)\n",
    "        for i, c in reversed(list(enumerate(out_classes))):\n",
    "            predicted_class = self.class_names[c]\n",
    "            box = out_boxes[i]\n",
    "            score = out_scores[i]\n",
    "            if score != max_score:\n",
    "                continue\n",
    "\n",
    "            label = '{} {:.2f}'.format(predicted_class, score)\n",
    "            draw = ImageDraw.Draw(image)\n",
    "            label_size = draw.textsize(label, font)\n",
    "\n",
    "            top, left, bottom, right = box\n",
    "            top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "            left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "            bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "            right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "            #print(label, (left, top), (right, bottom))\n",
    "\n",
    "            if top - label_size[1] >= 0:\n",
    "                text_origin = np.array([left, top - label_size[1]])\n",
    "            else:\n",
    "                text_origin = np.array([left, top + 1])\n",
    "\n",
    "            # My kingdom for a good redistributable image drawing library.\n",
    "            for i in range(thickness):\n",
    "                draw.rectangle(\n",
    "                    [left + i, top + i, right - i, bottom - i],\n",
    "                    outline=self.colors[c])\n",
    "            draw.rectangle(\n",
    "                [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "                fill=self.colors[c])\n",
    "            draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "            del draw\n",
    "            \n",
    "            return image, c, score, (left, top, right, bottom)  # x_min, y_min, x_max, y_max\n",
    "        \n",
    "        return image, None, None, None # (returns this if no sign is found)\n",
    "    \n",
    "        \n",
    "    def detect_all_signs(self, image):\n",
    "        \"\"\"\n",
    "        Will draw all the bounding boxes and return the list of classes, confidence scores\n",
    "        in the boxes and the boxes themselves.\n",
    "        \"\"\"\n",
    "        start = timer()\n",
    "\n",
    "        if self.model_image_size != (None, None):\n",
    "            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))\n",
    "        else:\n",
    "            new_image_size = (image.width - (image.width % 32),\n",
    "                              image.height - (image.height % 32))\n",
    "            boxed_image = letterbox_image(image, new_image_size)\n",
    "        image_data = np.array(boxed_image, dtype='float32')\n",
    "\n",
    "        #print(image_data.shape)\n",
    "        image_data /= 255.\n",
    "        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "        out_boxes, out_scores, out_classes = self.sess.run(\n",
    "            [self.boxes, self.scores, self.classes],\n",
    "            feed_dict={\n",
    "                self.yolo_model.input: image_data,\n",
    "                self.input_image_shape: [image.size[1], image.size[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "\n",
    "        #print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n",
    "\n",
    "        font = ImageFont.truetype(font='font/FiraMono-Medium.otf',\n",
    "                    size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "        thickness = (image.size[0] + image.size[1]) // 300\n",
    "        \n",
    "        list_c, list_score, list_box = [], [], []\n",
    "        for i, c in reversed(list(enumerate(out_classes))):\n",
    "            predicted_class = self.class_names[c]\n",
    "            box = out_boxes[i]\n",
    "            score = out_scores[i]\n",
    "\n",
    "            label = '{} {:.2f}'.format(predicted_class, score)\n",
    "            draw = ImageDraw.Draw(image)\n",
    "            label_size = draw.textsize(label, font)\n",
    "\n",
    "            top, left, bottom, right = box\n",
    "            top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "            left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "            bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "            right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "            #print(label, (left, top), (right, bottom))\n",
    "\n",
    "            if top - label_size[1] >= 0:\n",
    "                text_origin = np.array([left, top - label_size[1]])\n",
    "            else:\n",
    "                text_origin = np.array([left, top + 1])\n",
    "\n",
    "            # My kingdom for a good redistributable image drawing library.\n",
    "            for i in range(thickness):\n",
    "                draw.rectangle(\n",
    "                    [left + i, top + i, right - i, bottom - i],\n",
    "                    outline=self.colors[c])\n",
    "            draw.rectangle(\n",
    "                [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "                fill=self.colors[c])\n",
    "            draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "            del draw\n",
    "            \n",
    "            list_c.append(c)\n",
    "            list_score.append(score)\n",
    "            list_box.append((left, top, right, bottom)) # x_min, y_min, x_max, y_max\n",
    "        \n",
    "        return image, list_c, list_score, list_box  # (returns this if no sign is found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_img(img, yolo, all_bool=False):\n",
    "    \"\"\"\n",
    "    all_bool: whether or not to detect all signs in the picture\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image = Image.open(img)\n",
    "    except:\n",
    "        print('Open Error! Try again!')\n",
    "        return\n",
    "    else:\n",
    "        if all_bool:\n",
    "            r_image, label, score, box = yolo.detect_all_signs(image)\n",
    "        else:\n",
    "            r_image, label, score, box = yolo.detect_most_confident_sign(image)\n",
    "        #r_image.show()\n",
    "    return r_image, label, score, box\n",
    "    #yolo.close_session() x_min y_min x_max y_max\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    " \n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    " \n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    " \n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    " \n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n",
    "def prediction_ok(score, true_label, true_box, label, box):\n",
    "    # Wrong prediction if there is no box predicted,\n",
    "    # (/!\\ might need to change this if considering the \"no label\" images)\n",
    "    if score is None or label is None or box is None:\n",
    "        return False\n",
    "    \n",
    "    if score < 0.1:\n",
    "        return False\n",
    "    \n",
    "    if label != true_label:\n",
    "        return False\n",
    "    \n",
    "    if IoU(true_box, box) < 0.5:\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Accuracy computing </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the yolo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights/trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"weights/trained_weights_final.h5\"\n",
    "classes_path = \"model_data/lisa_classes.txt\"\n",
    "\n",
    "yolo = YOLOPlus(model_path=model_path, classes_path=classes_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Accuracy on train + validation dataset </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\louis\\documents\\python_virtual_env\\volvo\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LISA_TS_extension\\2014-04-24_10-59/frameAnnota...</td>\n",
       "      <td>958</td>\n",
       "      <td>329</td>\n",
       "      <td>1015</td>\n",
       "      <td>398</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LISA_TS\\aiua120306-1/frameAnnotations-DataLog0...</td>\n",
       "      <td>579</td>\n",
       "      <td>183</td>\n",
       "      <td>604</td>\n",
       "      <td>209</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LISA_TS\\vid4/frameAnnotations-vid_cmp2.avi_ann...</td>\n",
       "      <td>496</td>\n",
       "      <td>289</td>\n",
       "      <td>512</td>\n",
       "      <td>304</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LISA_TS_extension\\2014-05-01_16-29/2/frameAnno...</td>\n",
       "      <td>379</td>\n",
       "      <td>437</td>\n",
       "      <td>416</td>\n",
       "      <td>473</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LISA_TS_extension\\2014-07-11_12-12/1/frameAnno...</td>\n",
       "      <td>794</td>\n",
       "      <td>465</td>\n",
       "      <td>824</td>\n",
       "      <td>496</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path  x_min  y_min  x_max  \\\n",
       "0  LISA_TS_extension\\2014-04-24_10-59/frameAnnota...    958    329   1015   \n",
       "1  LISA_TS\\aiua120306-1/frameAnnotations-DataLog0...    579    183    604   \n",
       "2  LISA_TS\\vid4/frameAnnotations-vid_cmp2.avi_ann...    496    289    512   \n",
       "3  LISA_TS_extension\\2014-05-01_16-29/2/frameAnno...    379    437    416   \n",
       "4  LISA_TS_extension\\2014-07-11_12-12/1/frameAnno...    794    465    824   \n",
       "\n",
       "   y_max  label  \n",
       "0    398    2.0  \n",
       "1    209    3.0  \n",
       "2    304   13.0  \n",
       "3    473    0.0  \n",
       "4    496    0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train_lisa.txt\", sep=' |,', names=[\"file_path\", \"x_min\", \"y_min\", \"x_max\", \"y_max\", \"label\"])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670eae5e106e44c194d44028d330b32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "average accuracy (train):  80.0 %\n"
     ]
    }
   ],
   "source": [
    "n_examples = 30\n",
    "indices = np.random.choice(len(train_df), n_examples, replace=False)\n",
    "\n",
    "n_good_predictions = 0\n",
    "wrong_images = []\n",
    "labels = []\n",
    "true_labels = []\n",
    "true_boxes = []\n",
    "for index in tqdm(indices):\n",
    "    input_path = train_df[\"file_path\"][index]\n",
    "    #r_image, label, score, box = detect_img(input_path, yolo, all_bool=False)\n",
    "    r_image, labels, scores, boxes = detect_img(input_path, yolo, all_bool=True)\n",
    "\n",
    "\n",
    "    true_box = (train_df[\"x_min\"][index],\n",
    "                train_df[\"y_min\"][index],\n",
    "                train_df[\"x_max\"][index],\n",
    "                train_df[\"y_max\"][index])\n",
    "    true_label = train_df[\"label\"][index]\n",
    "    \n",
    "    pred_ok = False\n",
    "    for label, score, box in zip(labels, scores, boxes):\n",
    "        pred_ok = pred_ok or prediction_ok(score, true_label, true_box, label, box)\n",
    "    n_good_predictions += pred_ok\n",
    "    \n",
    "    # *** Uncomment these 4 lines to print the wrong predictions ***\n",
    "    if not pred_ok:\n",
    "        r_image.show()\n",
    "        wrong_images.append(r_image)\n",
    "        true_labels.append(true_label)\n",
    "        true_boxes.append(true_box)\n",
    "        \n",
    "\n",
    "print(\"average accuracy (train): \", round((n_good_predictions * 100)/n_examples, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turnRight (421, 209, 466, 252)\n"
     ]
    }
   ],
   "source": [
    "image, label, box = wrong_images[index], true_labels[index], true_boxes[index]\n",
    "image.show()\n",
    "index += 1\n",
    "print(yolo.class_names[label], box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy (train):  74.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"average accuracy (train): \", round((n_good_predictions * 100)/n_examples, 2), \"%\")\n",
    "# average accuracy:  79.89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Accuracy on extension dataset </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\louis\\documents\\python_virtual_env\\volvo\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LISA_TS_extension\\2014-04-24_10-59/frameAnnota...</td>\n",
       "      <td>1071</td>\n",
       "      <td>384</td>\n",
       "      <td>1116</td>\n",
       "      <td>432</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LISA_TS_extension\\2014-04-24_10-59/frameAnnota...</td>\n",
       "      <td>1129</td>\n",
       "      <td>367</td>\n",
       "      <td>1182</td>\n",
       "      <td>425</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LISA_TS_extension\\2014-04-24_10-59/frameAnnota...</td>\n",
       "      <td>691</td>\n",
       "      <td>429</td>\n",
       "      <td>728</td>\n",
       "      <td>467</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LISA_TS_extension\\2014-04-24_10-59/frameAnnota...</td>\n",
       "      <td>703</td>\n",
       "      <td>426</td>\n",
       "      <td>743</td>\n",
       "      <td>467</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LISA_TS_extension\\2014-04-24_10-59/frameAnnota...</td>\n",
       "      <td>720</td>\n",
       "      <td>417</td>\n",
       "      <td>764</td>\n",
       "      <td>466</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path  x_min  y_min  x_max  \\\n",
       "0  LISA_TS_extension\\2014-04-24_10-59/frameAnnota...   1071    384   1116   \n",
       "1  LISA_TS_extension\\2014-04-24_10-59/frameAnnota...   1129    367   1182   \n",
       "2  LISA_TS_extension\\2014-04-24_10-59/frameAnnota...    691    429    728   \n",
       "3  LISA_TS_extension\\2014-04-24_10-59/frameAnnota...    703    426    743   \n",
       "4  LISA_TS_extension\\2014-04-24_10-59/frameAnnota...    720    417    764   \n",
       "\n",
       "   y_max  label  \n",
       "0    432   36.0  \n",
       "1    425   36.0  \n",
       "2    467   18.0  \n",
       "3    467   18.0  \n",
       "4    466   18.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test_lisa.txt\", sep=' |,', names=[\"file_path\", \"x_min\", \"y_min\", \"x_max\", \"y_max\", \"label\"])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3f5505486746fba37372b8b1a32995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy (test):  52.0 %\n"
     ]
    }
   ],
   "source": [
    "n_examples = 100  # len(test_df)\n",
    "indices = np.random.choice(len(test_df), n_examples, replace=False)\n",
    "\n",
    "n_good_predictions = 0\n",
    "wrong_images = []\n",
    "labels = []\n",
    "true_labels = []\n",
    "true_boxes = []\n",
    "for index in tqdm(indices):\n",
    "    input_path = test_df[\"file_path\"][index]\n",
    "    #r_image, label, score, box = detect_img(input_path, yolo, all_bool=False)\n",
    "    r_image, labels, scores, boxes = detect_img(input_path, yolo, all_bool=True)\n",
    "\n",
    "\n",
    "    true_box = (test_df[\"x_min\"][index],\n",
    "                test_df[\"y_min\"][index],\n",
    "                test_df[\"x_max\"][index],\n",
    "                test_df[\"y_max\"][index])\n",
    "    true_label = test_df[\"label\"][index]\n",
    "    \n",
    "    pred_ok = False\n",
    "    for label, score, box in zip(labels, scores, boxes):\n",
    "        pred_ok = pred_ok or prediction_ok(score, true_label, true_box, label, box)\n",
    "    n_good_predictions += pred_ok\n",
    "    \n",
    "    # *** Uncomment these 2 lines to print the wrong predictions ***\n",
    "    if not pred_ok:\n",
    "        r_image.show()\n",
    "        wrong_images.append(r_image)\n",
    "        true_labels.append(true_label)\n",
    "        true_boxes.append(true_box)\n",
    "\n",
    "print(\"average accuracy (test): \", round((n_good_predictions * 100)/n_examples, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speedLimit25 (324, 446, 348, 486)\n"
     ]
    }
   ],
   "source": [
    "image, label, box = wrong_images[index], true_labels[index], true_boxes[index]\n",
    "image.show()\n",
    "index += 1\n",
    "print(yolo.class_names[int(label)], box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy (test):  48.56 %\n"
     ]
    }
   ],
   "source": [
    "print(\"average accuracy (test): \", round((n_good_predictions * 100)/n_examples, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Results summary </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> With test data set = extension data set </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Metric | train + validation | test        |\n",
    "|--------|--------------------|-------------|\n",
    "|Accuracy| **74.0%**          | **48.56%**   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy on the train+validation dataset overall (the original LISA dataset): 74.0%\n",
    "- Accuracy on the test dataset (the extension LISA dataset): 48.56%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> With test data set = 20% of (original dataset + extension dataset) </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Metric | train + validation | test        |\n",
    "|--------|--------------------|-------------|\n",
    "|Accuracy| **TO DO**          | **TO DO**   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Analysis & comments </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is clearly overfitting the original dataset, interestingly it is overfitting the train and the validation dataset, meaning that the dataset is not diversified enough -> the data augmentation will help a lot, the extension dataset was not used for training so we can try training it on it as well and see the improvement of the accuracy (on the LISA dataset as well as on real world pictures).\n",
    "\n",
    "The main reasons that lower the accuracy are the following:\n",
    "- There are quite some pictures where there are two signs or more (but still only 1 is labelled), YOLO will detect all signs or only some of them, and in the accuracy computation, only the first detected sign is considered\n",
    "- YOLO will sometimes say there is no sign on a picture that contains signs\n",
    "- YOLO will sometimes identify the sign and its position right but predict a wrong close class (like speed limit 35 instead of speed limit 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no obvious way to compute the accuracy for a detection task, a custom function was used to say whether or not a prediction is considered good, it might need to be changed. (An improvement would be to use the mAP metric: https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173)\n",
    "\n",
    "These are the criterions to consider a prediction good (Only the first prediction is considered, all others are ignored (there must a smarter way indeed...)):\n",
    "- There must be at least 1 prediction\n",
    "- The predicted label must be the same as the true label\n",
    "- The confidence score must be greater than 0.3\n",
    "- The Intersection over Union of the predicted and ground truth bounding boxes must be greater than 0.5\n",
    "\n",
    "/!\\ The accuracy was only computed for images that actually contain signs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
