{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Visualization YOLO efficiency </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to have run the following commands before running this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python pre_process_lisa.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also be sure to have the following folder architecture:\n",
    "- LISA_TS/\n",
    "    - aiua120214-0/\n",
    "    - aiua120214-1/\n",
    "    - ...\n",
    "    - readme.txt\n",
    "    - videoSources.txt\n",
    "    \n",
    "    \n",
    "- LISA_TS_extension/\n",
    "    - 2014-04-24_10-59/\n",
    "    - 2014-04-24_11-43/\n",
    "    - ...\n",
    "    - 2014-07-11_13-47/\n",
    "    - allTrainingAnnotations.csv\n",
    "    \n",
    "    \n",
    "- weights/\n",
    "    - trained_weights_final.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(To obtain *trained_weights_final.h5* either:\n",
    "- train the network by running *python train.py* (follow the readme instructions for more information, it needs a GPU and takes ~2 days for 150 epochs)\n",
    "- or ask Louis for the last trained weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Utils definition </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from yolo import YOLO\n",
    "from yolo3.utils import letterbox_image\n",
    "from yolo3.model import yolo_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOPlus(YOLO):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(YOLOPlus, self).__init__(**kwargs)\n",
    "\n",
    "    def detect_image_plus(self, image):\n",
    "        start = timer()\n",
    "\n",
    "        if self.model_image_size != (None, None):\n",
    "            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))\n",
    "        else:\n",
    "            new_image_size = (image.width - (image.width % 32),\n",
    "                              image.height - (image.height % 32))\n",
    "            boxed_image = letterbox_image(image, new_image_size)\n",
    "        image_data = np.array(boxed_image, dtype='float32')\n",
    "\n",
    "        #print(image_data.shape)\n",
    "        image_data /= 255.\n",
    "        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "        out_boxes, out_scores, out_classes = self.sess.run(\n",
    "            [self.boxes, self.scores, self.classes],\n",
    "            feed_dict={\n",
    "                self.yolo_model.input: image_data,\n",
    "                self.input_image_shape: [image.size[1], image.size[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "\n",
    "        #print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n",
    "\n",
    "        font = ImageFont.truetype(font='font/FiraMono-Medium.otf',\n",
    "                    size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "        thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "        for i, c in reversed(list(enumerate(out_classes))):\n",
    "            predicted_class = self.class_names[c]\n",
    "            box = out_boxes[i]\n",
    "            score = out_scores[i]\n",
    "\n",
    "            label = '{} {:.2f}'.format(predicted_class, score)\n",
    "            draw = ImageDraw.Draw(image)\n",
    "            label_size = draw.textsize(label, font)\n",
    "\n",
    "            top, left, bottom, right = box\n",
    "            top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "            left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "            bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "            right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "            #print(label, (left, top), (right, bottom))\n",
    "\n",
    "            if top - label_size[1] >= 0:\n",
    "                text_origin = np.array([left, top - label_size[1]])\n",
    "            else:\n",
    "                text_origin = np.array([left, top + 1])\n",
    "\n",
    "            # My kingdom for a good redistributable image drawing library.\n",
    "            for i in range(thickness):\n",
    "                draw.rectangle(\n",
    "                    [left + i, top + i, right - i, bottom - i],\n",
    "                    outline=self.colors[c])\n",
    "            draw.rectangle(\n",
    "                [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "                fill=self.colors[c])\n",
    "            draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "            del draw\n",
    "            \n",
    "            # for now only considers the first prediction because the LISA dataset\n",
    "            # has a maximum of 1 labeled sign per image, /!\\ need to change this\n",
    "            return image, c, score, (left, top, right, bottom)  # x_min, y_min, x_max, y_max\n",
    "        \n",
    "        return image, None, None, None # (returns this if no sign is found)\n",
    "        # end = timer()\n",
    "        # print(end - start)\n",
    "        # return image\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_img(img, yolo):\n",
    "    try:\n",
    "        image = Image.open(img)\n",
    "    except:\n",
    "        print('Open Error! Try again!')\n",
    "        return\n",
    "    else:\n",
    "        r_image, label, score, box = yolo.detect_image_plus(image)\n",
    "        #r_image.show()\n",
    "    return r_image, label, score, box\n",
    "    #yolo.close_session() x_min y_min x_max y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    " \n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    " \n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    " \n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    " \n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n",
    "def prediction_ok(score, true_label, true_box, label, box):\n",
    "    # Wrong prediction if there is no box predicted,\n",
    "    # (/!\\ might need to change this if considering the \"no label\" images)\n",
    "    if score is None or label is None or box is None:\n",
    "        return False\n",
    "    \n",
    "    if score < 0.3:\n",
    "        return False\n",
    "    \n",
    "    if label != true_label:\n",
    "        return False\n",
    "    \n",
    "    if IoU(true_box, box) < 0.5:\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Accuracy computing </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the yolo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"weights/trained_weights_final.h5\"\n",
    "classes_path = \"model_data/lisa_classes.txt\"\n",
    "\n",
    "yolo = YOLOPlus(model_path=model_path, classes_path=classes_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Accuracy on train + validation dataset </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\louis\\documents\\python_virtual_env\\volvo\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LISA_TS/aiua120214-0/frameAnnotations-DataLog0...</td>\n",
       "      <td>862</td>\n",
       "      <td>104</td>\n",
       "      <td>916</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LISA_TS/aiua120214-0/frameAnnotations-DataLog0...</td>\n",
       "      <td>425</td>\n",
       "      <td>197</td>\n",
       "      <td>438</td>\n",
       "      <td>213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LISA_TS/aiua120214-0/frameAnnotations-DataLog0...</td>\n",
       "      <td>922</td>\n",
       "      <td>88</td>\n",
       "      <td>982</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LISA_TS/aiua120214-0/frameAnnotations-DataLog0...</td>\n",
       "      <td>447</td>\n",
       "      <td>193</td>\n",
       "      <td>461</td>\n",
       "      <td>210</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LISA_TS/aiua120214-0/frameAnnotations-DataLog0...</td>\n",
       "      <td>469</td>\n",
       "      <td>189</td>\n",
       "      <td>483</td>\n",
       "      <td>207</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path  x_min  y_min  x_max  \\\n",
       "0  LISA_TS/aiua120214-0/frameAnnotations-DataLog0...    862    104    916   \n",
       "1  LISA_TS/aiua120214-0/frameAnnotations-DataLog0...    425    197    438   \n",
       "2  LISA_TS/aiua120214-0/frameAnnotations-DataLog0...    922     88    982   \n",
       "3  LISA_TS/aiua120214-0/frameAnnotations-DataLog0...    447    193    461   \n",
       "4  LISA_TS/aiua120214-0/frameAnnotations-DataLog0...    469    189    483   \n",
       "\n",
       "   y_max  label  \n",
       "0    158      0  \n",
       "1    213      1  \n",
       "2    148      0  \n",
       "3    210      2  \n",
       "4    207      2  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train_lisa.txt\", sep=' |,', names=[\"file_path\", \"x_min\", \"y_min\", \"x_max\", \"y_max\", \"label\"])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc313dd4fe114496acca0ce234440661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy:  74.0 %\n"
     ]
    }
   ],
   "source": [
    "n_examples = 100\n",
    "indices = np.random.choice(len(train_df), n_examples, replace=False)\n",
    "\n",
    "n_good_predictions = 0\n",
    "for index in tqdm(indices):\n",
    "    input_path = train_df[\"file_path\"][index]\n",
    "    r_image, label, score, box = detect_img(input_path, yolo)\n",
    "\n",
    "    true_box = (train_df[\"x_min\"][index],\n",
    "                train_df[\"y_min\"][index],\n",
    "                train_df[\"x_max\"][index],\n",
    "                train_df[\"y_max\"][index])\n",
    "    true_label = train_df[\"label\"][index]\n",
    "\n",
    "    n_good_predictions += prediction_ok(score, true_label, true_box, label, box)\n",
    "    \n",
    "    # *** Uncomment these 2 lines to print the wrong predictions ***\n",
    "    # if not prediction_ok(score, true_label, true_box, label, box):\n",
    "    #     r_image.show()\n",
    "\n",
    "print(\"average accuracy (train): \", round((n_good_predictions * 100)/n_examples, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy (train):  74.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"average accuracy (train): \", round((n_good_predictions * 100)/n_examples, 2), \"%\")\n",
    "# average accuracy:  79.89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Accuracy on extension dataset </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\louis\\documents\\python_virtual_env\\volvo\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LISA_TS_extension\\2014-04-24_10-59/frameAnnota...</td>\n",
       "      <td>1071</td>\n",
       "      <td>384</td>\n",
       "      <td>1116</td>\n",
       "      <td>432</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LISA_TS_extension\\2014-04-24_10-59/frameAnnota...</td>\n",
       "      <td>1129</td>\n",
       "      <td>367</td>\n",
       "      <td>1182</td>\n",
       "      <td>425</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LISA_TS_extension\\2014-04-24_10-59/frameAnnota...</td>\n",
       "      <td>691</td>\n",
       "      <td>429</td>\n",
       "      <td>728</td>\n",
       "      <td>467</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LISA_TS_extension\\2014-04-24_10-59/frameAnnota...</td>\n",
       "      <td>703</td>\n",
       "      <td>426</td>\n",
       "      <td>743</td>\n",
       "      <td>467</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LISA_TS_extension\\2014-04-24_10-59/frameAnnota...</td>\n",
       "      <td>720</td>\n",
       "      <td>417</td>\n",
       "      <td>764</td>\n",
       "      <td>466</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path  x_min  y_min  x_max  \\\n",
       "0  LISA_TS_extension\\2014-04-24_10-59/frameAnnota...   1071    384   1116   \n",
       "1  LISA_TS_extension\\2014-04-24_10-59/frameAnnota...   1129    367   1182   \n",
       "2  LISA_TS_extension\\2014-04-24_10-59/frameAnnota...    691    429    728   \n",
       "3  LISA_TS_extension\\2014-04-24_10-59/frameAnnota...    703    426    743   \n",
       "4  LISA_TS_extension\\2014-04-24_10-59/frameAnnota...    720    417    764   \n",
       "\n",
       "   y_max  label  \n",
       "0    432   36.0  \n",
       "1    425   36.0  \n",
       "2    467   18.0  \n",
       "3    467   18.0  \n",
       "4    466   18.0  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test_lisa.txt\", sep=' |,', names=[\"file_path\", \"x_min\", \"y_min\", \"x_max\", \"y_max\", \"label\"])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abaabfbf956e4a8baa3f94b3481325c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3672), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy (test):  48.56 %\n"
     ]
    }
   ],
   "source": [
    "n_examples = len(test_df)\n",
    "indices = np.random.choice(len(test_df), n_examples, replace=False)\n",
    "\n",
    "n_good_predictions = 0\n",
    "for index in tqdm(indices):\n",
    "    input_path = test_df[\"file_path\"][index]\n",
    "    r_image, label, score, box = detect_img(input_path, yolo)\n",
    "\n",
    "    true_box = (test_df[\"x_min\"][index],\n",
    "                test_df[\"y_min\"][index],\n",
    "                test_df[\"x_max\"][index],\n",
    "                test_df[\"y_max\"][index])\n",
    "    true_label = test_df[\"label\"][index]\n",
    "\n",
    "    n_good_predictions += prediction_ok(score, true_label, true_box, label, box)\n",
    "    \n",
    "    # *** Uncomment these 2 lines to print the wrong predictions ***\n",
    "    #if not prediction_ok(score, true_label, true_box, label, box):\n",
    "    #    r_image.show()\n",
    "\n",
    "print(\"average accuracy (test): \", round((n_good_predictions * 100)/n_examples, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy (test):  48.56 %\n"
     ]
    }
   ],
   "source": [
    "print(\"average accuracy (test): \", round((n_good_predictions * 100)/n_examples, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Results summary </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Metric | train + validation | test        |\n",
    "|--------|--------------------|-------------|\n",
    "|Accuracy| **74.0%**          | **48.56%**   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy on the train+validation dataset overall (the original LISA dataset): 74.0%\n",
    "- Accuracy on the test dataset (the extension LISA dataset): 48.56%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Analysis & comments </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is clearly overfitting the original dataset -> the data augmentation will help a lot, the extension dataset was not used for training so we can try training it on it as well and see the improvement of the accuracy (on the LISA dataset as well as on real world pictures).\n",
    "\n",
    "The main reasons that lower the accuracy are the following:\n",
    "- There are quite some pictures where there are two signs or more (but still only 1 is labelled), YOLO will detect all signs or only some of them, and in the accuracy computation, only the first detected sign is considered\n",
    "- YOLO will sometimes say there is no sign on a picture that contains signs\n",
    "- YOLO will sometimes identify the sign and its position right but predict a wrong close class (like speed limit 35 instead of speed limit 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no obvious way to compute the accuracy for a detection task, a custom function was used to say whether or not a prediction is considered good, it might need to be changed.\n",
    "\n",
    "These are the criterions to consider a prediction good (Only the first prediction is considered, all others are ignored (there must a smarter way indeed...)):\n",
    "- There must be at least 1 prediction\n",
    "- The predicted label must be the same as the true label\n",
    "- The confidence score must be greater than 0.3\n",
    "- The Intersection over Union of the predicted and ground truth bounding boxes must be greater than 0.5\n",
    "\n",
    "/!\\ The accuracy was only computed for images that actually contain signs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
